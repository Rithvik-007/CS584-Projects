{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "419e57fd-be04-4b60-b67f-2a0af69b4ed3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in d:\\gmu courses\\cs-584\\assignments\\hw1\\myenv\\lib\\site-packages (3.9.1)\n",
      "Requirement already satisfied: click in d:\\gmu courses\\cs-584\\assignments\\hw1\\myenv\\lib\\site-packages (from nltk) (8.1.7)\n",
      "Requirement already satisfied: joblib in d:\\gmu courses\\cs-584\\assignments\\hw1\\myenv\\lib\\site-packages (from nltk) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in d:\\gmu courses\\cs-584\\assignments\\hw1\\myenv\\lib\\site-packages (from nltk) (2024.9.11)\n",
      "Requirement already satisfied: tqdm in d:\\gmu courses\\cs-584\\assignments\\hw1\\myenv\\lib\\site-packages (from nltk) (4.66.5)\n",
      "Requirement already satisfied: colorama in d:\\gmu courses\\cs-584\\assignments\\hw1\\myenv\\lib\\site-packages (from click->nltk) (0.4.6)\n"
     ]
    }
   ],
   "source": [
    "!pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "34b345ce-714b-432e-a38f-eb2a5fcf01ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\rithv\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\rithv\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\rithv\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "import re \n",
    "from nltk import tokenize\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from scipy import sparse\n",
    "\n",
    "nltk.download('punkt_tab')\n",
    "nltk.download('stopwords')# Download the 'punkt' resource\n",
    "nltk.download('wordnet') # Download the 'wordnet' resource "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2606d61a-b719-442e-a79b-6d2d4a0c4886",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['C:\\\\Users\\\\rithv/nltk_data', 'D:\\\\GMU Courses\\\\CS-584\\\\Assignments\\\\HW1\\\\myenv\\\\nltk_data', 'D:\\\\GMU Courses\\\\CS-584\\\\Assignments\\\\HW1\\\\myenv\\\\share\\\\nltk_data', 'D:\\\\GMU Courses\\\\CS-584\\\\Assignments\\\\HW1\\\\myenv\\\\lib\\\\nltk_data', 'C:\\\\Users\\\\rithv\\\\AppData\\\\Roaming\\\\nltk_data', 'C:\\\\nltk_data', 'D:\\\\nltk_data', 'E:\\\\nltk_data']\n"
     ]
    }
   ],
   "source": [
    "print(nltk.data.path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f0c8d141-61c4-4d11-bf06-d65b1876372d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data = pd.read_csv(\"Train.txt\", delimiter=\"EOF\", on_bad_lines='skip')\n",
    "\n",
    "file = \"Train.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f76e29ba-ee3c-434a-82f6-28cdaf7950ec",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+1\tOne of my all-time favorite so-laughably-lousy-that-it's-totally-lovable el cheapo and stinko nickel'n'dime independent horror creature features, an enjoyably dreadful marvel that was released by the formidably fecund exploitation outfit Crown International Pictures so it could play numerous crappy double bills at countless drive-ins back in the 70's and eventually wound up being rerun like crazy on several small-time secondary cable stations throughout the 80's. I naturally first saw this gloriously ghastly abomination on late-night television one fateful Saturday evening while in my early teens and have had a deep-seated, albeit completely irrational abiding fondness for it ever since.<br /><br />A meteorite falls out of the sky and crashes into the still waters of a tranquil country lake, thereby causing a heretofore dormant dinosaur egg to hatch. Of course, the baby dino immediately grows into a gigantic waddling, grunting, teeth-gnashing prehistoric behemoth with goofy flippers, an extended neck and a huge mouth full of little sharp, jagged, stalagmite-like chompers. Our Southern-fried male cousin to the Loch Ness Monster promptly starts chowing down on various luckless local yokel residents of a previously quiet and sleepy hillbilly resort town. It's up to drippy stalwart sheriff Richard Cardella, assisted by the painfully idiotic hayseed comic relief brotherly fishing guide duo of Glenn Roberts and Mark Seigel, feisty gal pal Kacey Cobb and terminally insipid nerdy scientist Bob Hyman, to get to the bottom of things before the over-sized gluttonous Jurassic throwback ruins the tourist trade by eating all the campers and fisherman that the hick hamlet makes its cash off of.<br /><br />Director/co-screenwriter William R. Stromberg displays a wonderfully woeful and thoroughly clueless incompetence when it comes to pacing, atmosphere, taut narrative construction and especially eliciting sound, credible acting from his hopelessly all-thumbs rank amateur community theater level cast. The performances are uniformly abysmal: Cardella is way too bland and wooden to cut it as a solid heroic lead while the pitifully dopey redneck comic antics of Roberts and Seigel provoke groans of slack-jawed disbelief -- you aren't laughing with these two atrociously mugging clods so much as at them, particularly when the insufferable imbeciles discover a severed head bobbing up and down in the murky lake water. Better yet, a clumsily integrated sub-plot concerning a vicious on-the-loose criminal leads to a spectacularly ham-fisted supermarket hold-up scene which degenerates into a hilariously stupid mini-massacre when a young lady shopper interrupts the stick-up artist in mid-robbery! A subsequent car chase is likewise severely bungled as well; it's so limply staged and unimpressive that one feels more relieved than scared when the monster abruptly pops up to devour the nefarious fugitive. Moreover, David Allen's funky herky-jerky stop motion animation dinosaur is the authentic gnarly article, projecting a certain raw charisma, sneaky reptilian personality and overall forceful screen presence which makes all the horrendously underwhelming human characters seem like pathetically unbecoming nobody bores in comparison. And as for the rousing conclusion where the sheriff takes on our slavering beastie with a bulldozer, the operative word for this thrilling confrontation is boffo all the way. #EOF\n",
      "\n",
      "-1\tI had high hopes for this film, because I thought CLEAN, SHAVEN (Kerrigan's first feature) was absolutely terrific, the most assuredly cinematic low budget film I'd ever seen.<br /><br />But much of CLAIRE DOLAN is utterly pointless and flat. Scene after scene seems randomly tossed into the mix, without much thought for narrative or character.<br /><br />Is Claire trying to escape being a prostitute or not? Hard to tell. Why does she pick up the trick at the airport if she wants to escape that life? Why does she then not pick up tricks when she needs money in Seattle? Why do we have to see her dye her hair to what is virtually the exact same color? Why does Claire accept some johns and not others? The filmmaker doesn't seem to know.<br /><br />It feels as if everything is improvised (though I understand this wasn't the case) and the filmmakers just held a camera on it as if they were making a verite documentary.<br /><br />After the screening I saw, Kerrigan defended his lack of narrative choices by condemning film narrative as politically conservative. It sounded like learned rhetoric. I think it was a cop-out.<br /><br />I am saddened that the maker of a film as exciting as CLEAN, SHAVEN would go on to make such a lame film as this one and then defend it with tired old \"political\" cliches. #EOF\n",
      "\n",
      "-1\tWhen this was released, I thought this was one of the most profane films ever made. However, thanks to Martin Scorcese and a few other filmmakers like him, there have been mainline films worse, language-wise, than this....but this is a pretty brutal assault on one's ears. Hey, I can take a lot of it, but this got ridiculous. In the first six minutes alone, I heard a half-dozen usage's of the Lord's name in vain plus an untold number of f-words. I wonder how many people walked out of the theater watching this in 1990? I couldn't have been the only one.<br /><br />Not surprisingly, some of the feature actors included Jennifer Jason-Leigh, Burt Young, Jerry Orbach and Rikki Lake. Since this film, Stephen Lang seems to have improved his image, at least playing the Godly \"Stonewall\" Jackson in \"Gods and Generals.\" Lang's role here is just the opposite: perhaps the worst trashy person in the film and a character who falls in love with a transvestite by the end of the film.<br /><br />Depressing, gloomy, semi-pornographic, repulsive: these are just a few of the adjectives people used - even some Liberal critics - in describing this story, which is painted even worse in the novel. Of course, some of the better-known critics, all extreme Libs, praised the movie. However, they were the only ones. Most critics were disgusted, as well almost all of the paying public. It's unbelievable that anyone could praise filth and garbage like this.<br /><br />Trust me on this: there are no good, likable characters in this entire movie. This is a mean, sick film: one of the worst of the \"modern era.\" That is, unless you enjoy seeing child abuse, drug abuse, teen prostitutes, on and on - two straight hours of nothing but atrocities and just plain evil people. No thanks. #EOF\n",
      "\n",
      "-1\tI just watched this movie on Starz. Let me go through a few things i thought could have been improved; the acting, writing, directing, special effects, camera crew, sound, and lighting. It also seemed as though the writers had no idea anything that had to do with the movie. Apparently back in 2007, when the dollar was stronger you could buy a super advanced stealth bomber that could go completely invisible for $75 million. Now-a-days those things cost about $3 billion and they cant go invisible. Apparently you can fly from the US to the middle east in an hour. There was a completely random lesbian scene, which I didn't mind, but it seemed like a lame attempt to get more guys to see it. The camera would randomly zoom in on actors and skip to random scenes. Oh yeah, since its a Steven Segal movie, its predictable as hell. All in all I rank it right up there with Snakes on a Plane. #EOF\n",
      "\n",
      "+1\tI loved it so much that I bought the DVD and the novel at the same time. The chemistry between the actors (including little Arthur) is amazing and thrilling.<br /><br />It could have used a bit more screen time for the yummy Frederick Lawrence (played by James Purefoy). And Gilbert Markham was amazingly \"on it\" from the very start of the movie. <br /><br />The one who most thrilled me via surprising shock and awe and wonder was Rupert Graves as Arthur Huntingdon. I adore him in Forsyte Saga, and all else I've seen him in. But he outdoes himself here as Arthur. In my wildest dreams I could not have pictured him playing a demented psycho such as Arthur Huntingdon. But he does. And I love it. And I love him. #EOF\n",
      "\n",
      "+1\tThings to Come is indeed a classic work of speculative fiction; both an essay on the destructive nature of war and the terrors of progress. It makes some surprising accurate depictions of the war that was to follow a few years later, but is woefully naive in it's Utopian ideals.<br /><br />Raymond Massey, Cedric Hardwicke, and Ralph Richardson make up a fine cast, although the drama is played more as a stage piece, than a work of cinema. There are grandiose, if somewhat stilted speeches, often delivered as if the actor is trying to reach the back of the theater. However, there are some profound words there. Is technology the savior of mankind, or the instrument of its destruction? The film is a visual feast, if one can detach oneself from the age of the effects. Sure, Hollywood is more sophisticated today, but rarely as inventive. For the imaginative, the third act is a treat: a world with underground cities, massive deco bombers, space cannons, gyro copters, and secret organizations of scientist saviors. It has all of the makings of a sci-fi pulp adventure, but instead uses the trappings for a philosophical exercise.<br /><br />Things to Come and Metropolis were the hallmarks of neolithic Hollywood science fiction cinema. They are operatic in scope, and visually inspiring. Technology has long left them behind, but their ideas still burst forth. There is an artistry there, one with more heart and emotion than the computer generated mass-produced cinema of today. These films are the products of artisans, not industrialists. #EOF\n",
      "\n",
      "+1\tIt's amazing that from a good, though not wonderful, film made back in the early Nineties, a whole franchise can grow. 'Stargate; SG1' is, without a doubt, a worthy addition to the science fiction genre and has the right to stand shoulder-to-shoulder with 'Star Trek' as the kings of sci-fi.<br /><br />Following on from the 1994 feature film 'Stargate', this series sees Stargate command (a military/science organisation) figuring out that the stargate system can be used to travel to various planets across the galaxy and beyond and the military sets up a number of teams to explore. SG1 is one such team, headed by military veteran Colonel Jack O'Neill, and includes archaeologist Doctor Daniel Jackson, military scientist Captain Samantha Carter and alien Teal'c, who has betrayed his overlord leaders in the hopes of one day freeing his people. Earth quickly makes an enemy of the Goa'uld, a parasitic race who use humans as hosts and think themselves equal to gods.<br /><br />The top-notch cast have much to be congratulated for in bringing this show to life. Richard Dean Anderson is perfect as the cynical and sarcastic O'Neill, who can shift from boyish to deadly in the blink of an eye. Michael Shanks, as Daniel, brings heart and an will of steel to the character, who has grown from wide-eyed innocence to darker and more hard-bitten as the show has progressed. Amanda Tapping, as Carter, has perfected the balance between depicting her character's femininity without comprising the fact she is a strong, intelligent military scientist. Christopher Judge is excellent as the aloof Teal'c, who is able to depict the character's emotions with subtlety. And Don S Davis is perfect as the esteemed General Hammond who leads with a good balance of fairness and firmness.<br /><br />Almost all the episodes are are involving and portrayed with intelligence, reflecting on moral dilemmas as well as the friction between military interests and civilian beliefs (often shown through arguments between O'Neill and Jackson). Guest characters are solidly depicted and story arcs are handled in a manner that doesn't bore viewers. SG1 also excels in humour, from O'Neill's wisecracks to episodes that are just wacky and odd! SG1 has everything from action to drama to romance to suspense to the heartbreaking scenes of death. It isn't just an excellent sci-fi show but is an excellent show, overall. #EOF\n",
      "\n",
      "+1\tI wasn't alive in the 60's, so I can't guarantee that this movie was a completely accurate representation of the period, but it is certainly a moving and fulfilling experience. There are some excellent performances, most notably by Josh Hamilton (of With Honors), Jerry O'Connell (Sliders), who play brothers divided by the war. Bill Smitrovich, a character actor who has been long ignored by many, gives a heart-filled performance as their strict father, who is forced to question his own beliefs and values as one of his sons makes him proud by going to Vietnam but returns empty inside, while the other is exactly the opposite. All in all, this is a powerful and heartwarming film that I hope everyone gets a chance to experience. #EOF\n",
      "\n",
      "-1\tWilliam Shatner in small doses is tolerable. Unfortunately, instead of leaving his character as a minor irritation, and in that moderately amusing, it has been seen fit to enlarge his role and overdo it. Just as occurred in the original Star Trek series. I guess I will never understand American humour, which frequently goes 'over the top' to get the message through. I vote with my feet. I no longer watch the show, which is a shame, because the rest of the cast were good. It is pity that Shatner's overdone role also, affects James Spader's performance. But the majority demonstrate the way society is going, I guess. I don't travel the same routes. Frank #EOF\n",
      "\n",
      "-1\tThis movie is terrible. TERRIBLE. One of the worst movies ever. I cannot even imagine Gigli being worse that this. Previews made us say \"NO\", but then looking for something amid the dreck out there right now, we decided to go ahead and give it a shot.<br /><br />STUPID US.<br /><br />Affleck is NOT an actor. He's an image and can look good with explosions, but not even the kind Bruce Willis got in \"Die Hard\". If he stripped his shirt and ran around fighting bad guys, it would be a comedy.<br /><br />The best part was Catherine O'Hara -- she's always good. Gandolfini flops again (if it weren't for The Sopranos, he'd be washed up) like he did in \"The Mexican\".<br /><br />Affleck hogs every scene and as others have said -- no character has any motivation whatsoever for their actions. <br /><br />AVOID THIS MOVIE AT ALL COSTS. #EOF\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with open(\"Train.txt\") as f:\n",
    "    for _ in range(10):\n",
    "        print(f.readline())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fa91ee85-1b46-420e-81de-42a038b8f6e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('english'))\n",
    "unwanted_words = {\"br\"} \n",
    "\n",
    "def preprocess_text(text):\n",
    "    # Remove HTML tags like <br> and other unwanted characters\n",
    "    text = re.sub(r'<br\\s*/?>', ' ', text)\n",
    "    text = text.lower()  # Convert text to lowercase for uniformity\n",
    "    text = re.sub(r\"[^a-zA-Z0-9\\s']\", '', text)  # Remove punctuation\n",
    "\n",
    "    # Tokenize the text\n",
    "    word_tokens = word_tokenize(text)\n",
    "\n",
    "    # Lemmatizer to reduce words to their base form\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "    # Filter out stopwords and unwanted words, and lemmatize the remaining words\n",
    "    lemmas = [lemmatizer.lemmatize(word) for word in word_tokens if word not in stop_words and word not in unwanted_words]\n",
    "\n",
    "    return ' '.join(lemmas) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "89a3db19-7ea6-4156-ab44-42772820a87c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_reviews_from_file(file):\n",
    "    preprocessed_data = []\n",
    "    \n",
    "    with open(file, 'r', encoding='utf-8') as file:\n",
    "        for line in file:\n",
    "            if line.strip():  # Skip empty lines\n",
    "                # The label is at the beginning (+1 or -1), followed by the review text\n",
    "                label = int(line[0:2].strip())\n",
    "\n",
    "                # Replace the label -1 with 2 ( This is done because bincount doesn't accecpts negative characters )\n",
    "                if label == -1:\n",
    "                    label = 2\n",
    "\n",
    "                review = line[2:].strip()\n",
    "\n",
    "                # Removing \"EOF\" at the end of each para \n",
    "                if review.endswith(\"EOF\"):\n",
    "                    review = review[:-3].strip()  \n",
    "                review_text = preprocess_text(review)\n",
    "\n",
    "                # Append the result in the desired format\n",
    "                preprocessed_data.append([review_text, label])\n",
    "    return preprocessed_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3f9b12f4-b9b7-4fbe-8792-52818fef3865",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = process_reviews_from_file(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2264c5fa-8544-4ff9-96df-a9930554b0c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"thing come indeed classic work speculative fiction essay destructive nature war terror progress make surprising accurate depiction war follow year later woefully naive 's utopian ideal raymond massey cedric hardwicke ralph richardson make fine cast although drama played stage piece work cinema grandiose somewhat stilted speech often delivered actor trying reach back theater however profound word technology savior mankind instrument destruction film visual feast one detach oneself age effect sure hollywood sophisticated today rarely inventive imaginative third act treat world underground city massive deco bomber space cannon gyro copters secret organization scientist savior making scifi pulp adventure instead us trapping philosophical exercise thing come metropolis hallmark neolithic hollywood science fiction cinema operatic scope visually inspiring technology long left behind idea still burst forth artistry one heart emotion computer generated massproduced cinema today film product artisan industrialist\",\n",
       " 1]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "70072158-b7a3-4729-905a-db60ffa416de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Negative labels: []\n"
     ]
    }
   ],
   "source": [
    "labels = [item[1] for item in data]\n",
    "print(\"Negative labels:\", [label for label in labels if label < 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d7b6e40b-df84-477c-aa7a-6c2d4bf94d47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def remove_eof(data):\n",
    "#     for item in data:  # Iterate over each dictionary in the list\n",
    "#         if 'reviews' in item:  # Check if 'reviews' key exists\n",
    "#             if isinstance(item['reviews'], list):\n",
    "#                 # Join list into a single string\n",
    "#                 item['reviews'] = ' '.join(item['reviews'])\n",
    "#             item['reviews'] = item['reviews'].replace(' eof', '')   # Remove \"eof\" with a preceding space for safety\n",
    "\n",
    "# # Call the function\n",
    "# remove_eof(data)   \n",
    "# data[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "594bf79f-2388-4b8d-aeff-16508962a7db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.DataFrame(data)\n",
    "# df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a6df43e8-4387-4d84-aaf2-fd95bc2e903e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vectorizer = TfidfVectorizer(stop_words='english')\n",
    "X_train = tfidf_vectorizer.fit_transform([df[0] for df in data])\n",
    "Y_train = [df[1] for df in data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "acfe26e9-2a2d-4a6f-a1a5-30adf58114ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "#len(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1dbed2dd-5146-4c70-b978-59c0fe3f02d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "dense_X = X_train\n",
    "non_zero_elements = dense_X[0][dense_X[0] != 0]  # Access row and filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a00e9f84-c7f9-4345-9c5a-5912366f241b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.03872687 0.03717451 0.06489936 0.05807961 0.05586876 0.05271872\n",
      "  0.02037524 0.04876381 0.04565178 0.08004175 0.0512202  0.0461312\n",
      "  0.03821737 0.0512202  0.05599855 0.04094828 0.06574032 0.03707612\n",
      "  0.06967116 0.0489781  0.03846078 0.07774554 0.07327881 0.02150423\n",
      "  0.04461285 0.0459806  0.07327881 0.07774554 0.04664127 0.06833777\n",
      "  0.06897666 0.08327809 0.04480366 0.06043263 0.03346181 0.16008351\n",
      "  0.04636257 0.0243556  0.05174013 0.03649858 0.0168661  0.04977695\n",
      "  0.04010136 0.06668044 0.08327809 0.08327809 0.08004175 0.05513145\n",
      "  0.06114789 0.06489936 0.02158455 0.07248253 0.04418461 0.04331095\n",
      "  0.02971617 0.0514389  0.03917514 0.05307352 0.05298333 0.04977695\n",
      "  0.0348505  0.02746872 0.04835176 0.0461693  0.04583278 0.03814717\n",
      "  0.04100807 0.0489781  0.04110872 0.05791156 0.03360294 0.03612107\n",
      "  0.07221299 0.05916972 0.06833777 0.06166303 0.06530877 0.10302629\n",
      "  0.08327809 0.04777101 0.04464434 0.04320488 0.06043263 0.07127287\n",
      "  0.04358247 0.04572369 0.07450921 0.07450921 0.05093763 0.03147056\n",
      "  0.0462847  0.0554916  0.05599855 0.07450921 0.06221371 0.02744308\n",
      "  0.04568766 0.03701523 0.04740607 0.0514389  0.03080285 0.06280523\n",
      "  0.03201563 0.03239404 0.08004175 0.02500194 0.06221371 0.06280523\n",
      "  0.05727268 0.07221299 0.06193362 0.06967116 0.07774554 0.060664\n",
      "  0.06043263 0.05344483 0.05860607 0.05791156 0.0521334  0.06413862\n",
      "  0.07774554 0.07327881 0.04860679 0.05956889 0.0501454  0.07450921\n",
      "  0.04959891 0.06450993 0.05524971 0.06344411 0.07596446 0.03040096\n",
      "  0.07327881 0.07774554 0.050466   0.05791156 0.05316474 0.06020778\n",
      "  0.07127287 0.05456513 0.06450993 0.02794092 0.03485975 0.03104029\n",
      "  0.07450921 0.04959891 0.06719557 0.04033693 0.06043263 0.04400788\n",
      "  0.05478686 0.06344411 0.06193362 0.04499914 0.06280523 0.060664\n",
      "  0.06967116 0.06043263 0.08004175 0.03484125 0.09481213 0.06280523\n",
      "  0.03936826 0.05814411 0.03370645 0.02815486 0.05325702 0.08004175\n",
      "  0.02111761 0.03551563 0.07450921 0.08004175 0.0335621  0.03763292\n",
      "  0.03740042 0.05501493 0.06530877 0.08327809 0.08327809 0.07555681\n",
      "  0.04131392 0.04233237 0.06378381 0.05860607 0.04158881 0.04464434\n",
      "  0.04925432 0.06450993 0.06043263 0.07450921 0.07450921 0.04455025\n",
      "  0.08327809 0.06413862 0.0485038  0.03147056 0.06530877 0.04409576\n",
      "  0.0454748  0.0514389  0.03405033 0.06413862 0.02365468 0.04011923\n",
      "  0.03022806 0.07221299 0.02420553 0.04254778 0.06140131 0.04119017\n",
      "  0.04668189 0.06833777 0.05599855 0.06280523 0.04427446 0.04620758\n",
      "  0.04835176 0.05524971 0.03467667 0.04543986 0.06250399 0.06833777\n",
      "  0.05280595 0.05053169 0.0522963  0.03700311 0.06981237 0.05956889\n",
      "  0.04383499 0.04652063 0.02562042 0.04451913 0.01875258 0.04276917\n",
      "  0.02811402 0.05490008 0.16655617 0.05807961 0.05467523 0.04731738\n",
      "  0.0947232  0.07450921 0.04558052 0.07221299 0.07596446 0.06020778\n",
      "  0.06530877 0.06668044 0.08327809 0.03978625 0.03000321 0.08004175\n",
      "  0.060664   0.05197376 0.08327809 0.05977622 0.02659079 0.04297125\n",
      "  0.08004175 0.07596446 0.03331549 0.08327809 0.08327809 0.03145242\n",
      "  0.0484528  0.05086853 0.05998908 0.05878956 0.04176281 0.08327809\n",
      "  0.0362965  0.06719557 0.03457774 0.01935973 0.04235602 0.04876381\n",
      "  0.06193362 0.05403635 0.03450656 0.04983719 0.07774554 0.07450921\n",
      "  0.06378381 0.05536973 0.06090228 0.03843176 0.05151315 0.07596446\n",
      "  0.07896621 0.03769834 0.03930336 0.06221371 0.0431002  0.04304837\n",
      "  0.03022806 0.04948238 0.07596446 0.02574063]]\n"
     ]
    }
   ],
   "source": [
    "non_zero_elements = dense_X[0][dense_X[0] != 0]  # Filters the first row for non-zero elements.\n",
    "print(non_zero_elements)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f2ddbbe8-7d14-41ba-b737-fdf1ed884a60",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.sparse import csr_matrix\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "class KNN:\n",
    "    def __init__(self, k):\n",
    "        self.Y_train = None\n",
    "        self.X_train = None\n",
    "        self.k = k\n",
    "    \n",
    "    def fit(self, X_train, Y_train):\n",
    "        # Store the training data in sparse format if it isn't already\n",
    "        self.X_train = csr_matrix(X_train) if not isinstance(X_train, csr_matrix) else X_train\n",
    "        self.Y_train = Y_train\n",
    "    \n",
    "    def cosine_similarity(self, x, y):\n",
    "        # Convert x to a sparse matrix if it isn't already\n",
    "        x = csr_matrix(x) if not isinstance(x, csr_matrix) else x\n",
    "        y = csr_matrix(y) if not isinstance(y, csr_matrix) else y\n",
    "\n",
    "        # Compute the norms of each row vector in the sparse matrices\n",
    "        norms_vector = np.sqrt(x.multiply(x).sum(axis=1).A1)  # Efficient norm calculation for sparse data\n",
    "        norms_vectors = np.sqrt(y.multiply(y).sum(axis=1).A1)\n",
    "\n",
    "        # Avoid division by zero by handling zero or near-zero norms\n",
    "        norms_vector[norms_vector == 0] = 1e-10\n",
    "        norms_vectors[norms_vectors == 0] = 1e-10\n",
    "\n",
    "        # Compute the dot product between x and y using sparse matrix operations\n",
    "        dot_product = y.dot(x.T).toarray()  # Convert to a dense array for cosine similarity calculation\n",
    "\n",
    "        return dot_product / np.outer(norms_vectors, norms_vector)\n",
    "\n",
    "    def predict(self, x):\n",
    "        # Use cosine similarity to measure distances\n",
    "        cosine_similarity = self.cosine_similarity(x, self.X_train)\n",
    "\n",
    "        # Find k-nearest neighbors efficiently using argsort\n",
    "        knn_indices = np.argsort(cosine_similarity.T, axis=1)[:, -self.k:]\n",
    "\n",
    "        # Retrieve the labels for the k-nearest neighbors\n",
    "        knn_labels = self.Y_train[knn_indices]\n",
    "\n",
    "        # Predict the labels by finding the most common label among the neighbors\n",
    "        predictions = np.array([np.argmax(np.bincount(np.clip(labels.astype(int), 0, None))) for labels in knn_labels])\n",
    "\n",
    "        return predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "792b6e4d-0e9b-482e-b486-75cba3af6b68",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import sparse\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "def cross_validation(predictions, y_test):\n",
    "    true_positive = true_negative = false_positive = false_negative = 0    \n",
    "    for t_label, p_label in zip(y_test, predictions):\n",
    "        if t_label == 1 and p_label == 1:\n",
    "            true_positive += 1\n",
    "        elif t_label == 2 and p_label == 2:\n",
    "            true_negative += 1\n",
    "        elif t_label == 2 and p_label == 1:\n",
    "            false_positive += 1\n",
    "        elif t_label == 1 and p_label == 2:\n",
    "            false_negative += 1\n",
    "    return [true_positive, true_negative, false_positive, false_negative]\n",
    "\n",
    "def k_fold_cross_validation(x, y, folds, k):\n",
    "    accuracy_sum = 0\n",
    "\n",
    "    # Shuffle the data before splitting into folds\n",
    "    x, y = shuffle(x, y, random_state=42)\n",
    "    fold_size = x.shape[0] // folds\n",
    "    print(\"\\nFold Size: \" + str(fold_size))\n",
    "\n",
    "    for i in range(folds):\n",
    "        start_index = i * fold_size\n",
    "        end_index = (i + 1) * fold_size if i < (folds - 1) else x.shape[0]\n",
    "\n",
    "        # Split the data into training and validation sets using sparse slicing\n",
    "        x_val_fold = x[start_index:end_index]\n",
    "        x_train_fold = sparse.vstack([x[:start_index], x[end_index:]])\n",
    "\n",
    "        y_val_fold = y[start_index:end_index]\n",
    "        y_train_fold = np.concatenate([y[:start_index], y[end_index:]])\n",
    "\n",
    "        # Train the k-NN classifier with the current fold's training data\n",
    "        knn_classifier = KNN(k)\n",
    "        knn_classifier.fit(x_train_fold, y_train_fold)\n",
    "\n",
    "        # Predict the labels for the validation set\n",
    "        predictions = knn_classifier.predict(x_val_fold)\n",
    "        print(predictions)\n",
    "\n",
    "        # Calculate the confusion matrix for the current fold\n",
    "        confusion_matrix = cross_validation(predictions, y_val_fold)\n",
    "        accuracy_score = (confusion_matrix[0] + confusion_matrix[1]) / len(y_val_fold)\n",
    "        accuracy_sum += accuracy_score\n",
    "\n",
    "        print(f\"k: {k} ====== fold index: {i} ==== accuracy: {accuracy_score}\")\n",
    "\n",
    "    # Calculate the overall accuracy across all folds\n",
    "    overall_accuracy = accuracy_sum / folds\n",
    "    print(\"Overall Accuracy: \" + str(overall_accuracy))\n",
    "    return overall_accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b7c3f20c-875f-4b5d-9d86-5a84b6be3291",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fold Size: 4166\n",
      "[1 2 2 ... 2 2 1]\n",
      "k: 191 ====== fold index: 0 ==== accuracy: 0.8101296207393183\n",
      "[2 2 2 ... 1 1 1]\n",
      "k: 191 ====== fold index: 1 ==== accuracy: 0.8202112337974076\n",
      "[1 2 2 ... 2 2 2]\n",
      "k: 191 ====== fold index: 2 ==== accuracy: 0.8206913106096976\n",
      "[2 1 2 ... 2 2 1]\n",
      "k: 191 ====== fold index: 3 ==== accuracy: 0.828852616418627\n",
      "[1 1 2 ... 1 2 2]\n",
      "k: 191 ====== fold index: 4 ==== accuracy: 0.8125300048007681\n",
      "[1 2 1 ... 1 1 1]\n",
      "k: 191 ====== fold index: 5 ==== accuracy: 0.8172661870503597\n",
      "Overall Accuracy: 0.8182801622360296\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8182801622360296"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "\n",
    "#k_best = 2000  # Number of features to select\n",
    "#selector = SelectKBest(chi2, k=k_best)\n",
    "#X_train = selector.fit_transform(X_train, Y_train)\n",
    "folds = 6\n",
    "k_fold_cross_validation(X_train, Y_train, folds, k=191) # Randomly taking K as 7 for the base line model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb7be7bf-afc7-4e94-92a1-d533aad051bb",
   "metadata": {},
   "source": [
    "### Now lets Do Hyperparameter tuning inorder to find the best K neighbour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8c210b49-6387-4dfc-8fcd-be92998b1dc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# best_accuracy = 0\n",
    "# best_k = 0\n",
    "# accuracy_map = {}\n",
    "\n",
    "# # Test different k values from 10 to 400\n",
    "# for k in range(10, 401):\n",
    "#     accuracy = k_fold_cross_validation(X_train, Y_train, folds=6, k=k)\n",
    "#     accuracy_map[k] = accuracy\n",
    "#     if accuracy > best_accuracy:\n",
    "#         best_accuracy = accuracy\n",
    "#         best_k = k\n",
    "\n",
    "# print(f\"Best k value: {best_k} with accuracy: {best_accuracy}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d44cad33-c1dd-4eb2-a8a5-520d8e400f7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "Test_file = \"Test.txt\"\n",
    "preprocessed_test_data = []\n",
    "\n",
    "with open(Test_file, 'r', encoding='utf-8') as file:\n",
    "  for line in file:\n",
    "    if line.strip():\n",
    "        review_text = line.strip()\n",
    "        if review_text.endswith(\"EOF\"):\n",
    "          review = review_text[:-3].strip()  \n",
    "        review_text = preprocess_text(review)\n",
    "        preprocessed_test_data.append(review_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8e8a3287-4e15-45db-88f3-5a00c20a6aab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"low budget film set one location valley shielded effect radiation cast older man daughter handsome visitor couple tough buy gal drifter donkey radiation affected man interact effect nuclear blast added entity watching woman take bath gun get shot told child others murdered others drift away well movie harvey cormann 's first film show certain simplicity movie making avoid expensive set actor go curtain enter exit house ie studio location shot filmed hill near hollywood backdrop would say worth going way see interesting see movie human subject made 50\""
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessed_test_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b4036eda-f373-4c95-af63-98f74e8a8398",
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 4.46 GiB for an array with shape (598308375,) and data type float64",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[18], line 8\u001b[0m\n\u001b[0;32m      5\u001b[0m knn_classifier \u001b[38;5;241m=\u001b[39m KNN(k\u001b[38;5;241m=\u001b[39mbest_k_from_trained_model)\n\u001b[0;32m      6\u001b[0m knn_classifier\u001b[38;5;241m.\u001b[39mfit(X_train, np\u001b[38;5;241m.\u001b[39marray(Y_train))\n\u001b[1;32m----> 8\u001b[0m predictions \u001b[38;5;241m=\u001b[39m \u001b[43mknn_classifier\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m# Replace the label value 2 with -1, as this was done earlier in the training phase\u001b[39;00m\n\u001b[0;32m     11\u001b[0m predictions[predictions \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m\n",
      "Cell \u001b[1;32mIn[13], line 36\u001b[0m, in \u001b[0;36mKNN.predict\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpredict\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m     35\u001b[0m     \u001b[38;5;66;03m# Use cosine similarity to measure distances\u001b[39;00m\n\u001b[1;32m---> 36\u001b[0m     cosine_similarity \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcosine_similarity\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mX_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     38\u001b[0m     \u001b[38;5;66;03m# Find k-nearest neighbors efficiently using argsort\u001b[39;00m\n\u001b[0;32m     39\u001b[0m     knn_indices \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39margsort(cosine_similarity\u001b[38;5;241m.\u001b[39mT, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)[:, \u001b[38;5;241m-\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mk:]\n",
      "Cell \u001b[1;32mIn[13], line 30\u001b[0m, in \u001b[0;36mKNN.cosine_similarity\u001b[1;34m(self, x, y)\u001b[0m\n\u001b[0;32m     27\u001b[0m norms_vectors[norms_vectors \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1e-10\u001b[39m\n\u001b[0;32m     29\u001b[0m \u001b[38;5;66;03m# Compute the dot product between x and y using sparse matrix operations\u001b[39;00m\n\u001b[1;32m---> 30\u001b[0m dot_product \u001b[38;5;241m=\u001b[39m \u001b[43my\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mT\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mtoarray()  \u001b[38;5;66;03m# Convert to a dense array for cosine similarity calculation\u001b[39;00m\n\u001b[0;32m     32\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m dot_product \u001b[38;5;241m/\u001b[39m np\u001b[38;5;241m.\u001b[39mouter(norms_vectors, norms_vector)\n",
      "File \u001b[1;32mD:\\GMU Courses\\CS-584\\Assignments\\HW1\\myenv\\lib\\site-packages\\scipy\\sparse\\_base.py:416\u001b[0m, in \u001b[0;36mspmatrix.dot\u001b[1;34m(self, other)\u001b[0m\n\u001b[0;32m    414\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m \u001b[38;5;241m*\u001b[39m other\n\u001b[0;32m    415\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 416\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m@\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mother\u001b[49m\n",
      "File \u001b[1;32mD:\\GMU Courses\\CS-584\\Assignments\\HW1\\myenv\\lib\\site-packages\\scipy\\sparse\\_base.py:630\u001b[0m, in \u001b[0;36mspmatrix.__matmul__\u001b[1;34m(self, other)\u001b[0m\n\u001b[0;32m    627\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m isscalarlike(other):\n\u001b[0;32m    628\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mScalar operands are not allowed, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    629\u001b[0m                      \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muse \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m*\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m instead\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 630\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_mul_dispatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mother\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mD:\\GMU Courses\\CS-584\\Assignments\\HW1\\myenv\\lib\\site-packages\\scipy\\sparse\\_base.py:541\u001b[0m, in \u001b[0;36mspmatrix._mul_dispatch\u001b[1;34m(self, other)\u001b[0m\n\u001b[0;32m    539\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m!=\u001b[39m other\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]:\n\u001b[0;32m    540\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdimension mismatch\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m--> 541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_mul_sparse_matrix\u001b[49m\u001b[43m(\u001b[49m\u001b[43mother\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    543\u001b[0m \u001b[38;5;66;03m# If it's a list or whatever, treat it like a matrix\u001b[39;00m\n\u001b[0;32m    544\u001b[0m other_a \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masanyarray(other)\n",
      "File \u001b[1;32mD:\\GMU Courses\\CS-584\\Assignments\\HW1\\myenv\\lib\\site-packages\\scipy\\sparse\\_compressed.py:530\u001b[0m, in \u001b[0;36m_cs_matrix._mul_sparse_matrix\u001b[1;34m(self, other)\u001b[0m\n\u001b[0;32m    528\u001b[0m indptr \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mempty(major_axis \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m, dtype\u001b[38;5;241m=\u001b[39midx_dtype)\n\u001b[0;32m    529\u001b[0m indices \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mempty(nnz, dtype\u001b[38;5;241m=\u001b[39midx_dtype)\n\u001b[1;32m--> 530\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mempty\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnnz\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mupcast\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mother\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    532\u001b[0m fn \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(_sparsetools, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mformat \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_matmat\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    533\u001b[0m fn(M, N, np\u001b[38;5;241m.\u001b[39masarray(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindptr, dtype\u001b[38;5;241m=\u001b[39midx_dtype),\n\u001b[0;32m    534\u001b[0m    np\u001b[38;5;241m.\u001b[39masarray(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindices, dtype\u001b[38;5;241m=\u001b[39midx_dtype),\n\u001b[0;32m    535\u001b[0m    \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    538\u001b[0m    other\u001b[38;5;241m.\u001b[39mdata,\n\u001b[0;32m    539\u001b[0m    indptr, indices, data)\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 4.46 GiB for an array with shape (598308375,) and data type float64"
     ]
    }
   ],
   "source": [
    "X_test = tfidf_vectorizer.transform(preprocessed_test_data)\n",
    "#X_test = selector.transform(X_test)\n",
    "best_k_from_trained_model = 191\n",
    "\n",
    "knn_classifier = KNN(k=best_k_from_trained_model)\n",
    "knn_classifier.fit(X_train, np.array(Y_train))\n",
    "\n",
    "predictions = knn_classifier.predict(X_test)\n",
    "\n",
    "# Replace the label value 2 with -1, as this was done earlier in the training phase\n",
    "predictions[predictions == 2] = -1\n",
    "file_name = \"predictions.txt\"\n",
    "# Save the predictions to a file with a timestamped name\n",
    "with open(file_name, 'w+') as file:\n",
    "    for prediction in predictions:\n",
    "        file.write(str(prediction) + '\\n')\n",
    "\n",
    "print(f\"Predictions written to file: {file_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3bc6e33-49d2-42aa-a743-eefe98427c1c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
