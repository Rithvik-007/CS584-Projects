{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 414,
   "id": "e8b5733f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from scipy.sparse import csr_matrix \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "id": "96bde9be",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('train.txt', header = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "id": "67885340",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = []\n",
    "class_labels = []\n",
    "data1 = []\n",
    "row_indices = []\n",
    "col_indices = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "id": "56c659dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0, data.shape[0]):\n",
    "    data_point = list(filter(lambda x: x.strip() != \"\", data.iloc[i][0].replace(\"\\t\", \" \").split(\" \")))\n",
    "    data_point = list(map(int, data_point))\n",
    "    class_labels.append(data_point[0])\n",
    "    features.append(data_point[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "id": "78571c3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, indices in enumerate(features):\n",
    "    data1.extend([1] * len(indices)) \n",
    "    row_indices.extend([i] * len(indices))\n",
    "    col_indices.extend(indices)\n",
    "\n",
    "num_rows = len(features)\n",
    "num_columns = max(max(indices) for indices in features) + 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "id": "216ba993",
   "metadata": {},
   "outputs": [],
   "source": [
    "sparse_matrix = csr_matrix((data1, (row_indices, col_indices)), shape=(num_rows, num_columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ff6c275",
   "metadata": {},
   "source": [
    "# Tried Over Sampling and Under Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "id": "436b98c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# oversampler = RandomOverSampler(sampling_strategy='minority')\n",
    "# X_resampled, y_resampled = oversampler.fit_resample(sparse_matrix, class_labels)\n",
    "# smote = SMOTE()\n",
    "# X_resampled, y_resampled = smote.fit_resample(sparse_matrix, class_labels)\n",
    "# undersampler = RandomUnderSampler(sampling_strategy='majority')\n",
    "# X_resampled, y_resampled = undersampler.fit_resample(sparse_matrix, class_labels)\n",
    "\n",
    "# over = SMOTE(sampling_strategy=0.5)\n",
    "# under = RandomUnderSampler(sampling_strategy=0.5)\n",
    "# steps = [('o', over), ('u', under)]\n",
    "# pipeline = Pipeline(steps=steps)\n",
    "# # transform the dataset\n",
    "# X, y = pipeline.fit_resample(sparse_matrix, class_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "id": "62fce98c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(sparse_matrix, class_labels, test_size=0.2, random_state=42, stratify=class_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "id": "1ffea132",
   "metadata": {},
   "outputs": [],
   "source": [
    "k_best = SelectKBest(score_func=chi2, k=350)  \n",
    "\n",
    "X_train_new = k_best.fit_transform(X_train, y_train)\n",
    "X_test_new = k_best.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fd42833",
   "metadata": {},
   "source": [
    "# KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "id": "e8e7f453",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.4\n"
     ]
    }
   ],
   "source": [
    "\n",
    "neigh = KNeighborsClassifier(n_neighbors=20)\n",
    "neigh.fit(X_train_new, y_train)\n",
    "y_pred = neigh.predict(X_test_new)\n",
    "accuracy = f1_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "963a2d4f",
   "metadata": {},
   "source": [
    "# Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "id": "538d52de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score: 0.55\n"
     ]
    }
   ],
   "source": [
    "clf = GaussianNB()\n",
    "\n",
    "\n",
    "clf.fit(X_train_new.toarray(), y_train)\n",
    "\n",
    "\n",
    "y_pred = clf.predict(X_test_new.toarray())\n",
    "\n",
    "\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "print(f\"F1 Score: {f1:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec93565d",
   "metadata": {},
   "source": [
    "# Desicion Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "id": "75a7e983",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score: 0.7775249652382759\n"
     ]
    }
   ],
   "source": [
    "dt_classifier = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "\n",
    "dt_classifier.fit(X_train_new, y_train)\n",
    "\n",
    "\n",
    "y_pred = dt_classifier.predict(X_test_new)\n",
    "\n",
    "\n",
    "f1 = f1_score(y_test, y_pred, average='macro')\n",
    "print(f\"F1 Score: {f1}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17a63f49",
   "metadata": {},
   "source": [
    "# MLP with bucketing technique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "id": "4bbe6e60",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lokeshwaran/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/lokeshwaran/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/lokeshwaran/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/lokeshwaran/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/lokeshwaran/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "active_indices = np.where(np.array(y_train) == 1)[0]\n",
    "inactive_indices = np.where(np.array(y_train) == 0)[0]\n",
    "y_train = np.array(y_train)\n",
    "\n",
    "all_predictions = []\n",
    "used_inactive_indices = []\n",
    "\n",
    "\n",
    "num_models = 10  \n",
    "for i in range(num_models):\n",
    "    \n",
    "    num_inactive_samples = min(150, len(inactive_indices))\n",
    "\n",
    "    \n",
    "    unused_inactive_indices = list(set(inactive_indices) - set(used_inactive_indices))\n",
    "\n",
    "    \n",
    "    if len(unused_inactive_indices) < num_inactive_samples:\n",
    "        unused_inactive_indices = list(set(inactive_indices))\n",
    "\n",
    "    random_inactive_indices = np.random.choice(unused_inactive_indices, num_inactive_samples, replace=False)\n",
    "\n",
    "   \n",
    "    used_inactive_indices.extend(random_inactive_indices)\n",
    "\n",
    "    \n",
    "    balanced_indices = np.concatenate([active_indices, random_inactive_indices])\n",
    "\n",
    "\n",
    "    \n",
    "    X_balanced = X_train[balanced_indices]\n",
    "    y_balanced = y_train[balanced_indices]\n",
    "    X_train_new = k_best.fit_transform(X_balanced, y_balanced)\n",
    "    \n",
    "  \n",
    "    model = MLPClassifier(hidden_layer_sizes=(64, 32), alpha=1e-5, activation='relu', solver='adam', random_state=42)\n",
    " \n",
    "    model.fit(X_train_new, y_balanced)\n",
    "    X_test_new = k_best.transform(X_test)\n",
    "    \n",
    "    y_pred = model.predict(X_test_new)\n",
    "\n",
    "   \n",
    "    all_predictions.append(y_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "id": "f7381f7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1\n",
      " 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 1 0 0 0 1 0 0 1 0 0 0 0\n",
      " 0 0 0 0 1 0 1 1 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1\n",
      " 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 1 1 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 1 0\n",
      " 1 0 0 0 1 0 1 1 0 0 0 1]\n"
     ]
    }
   ],
   "source": [
    "y_pred = np.any(all_predictions, axis=0).astype(int)\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "id": "e52ebf74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score: 0.7207235798159315\n"
     ]
    }
   ],
   "source": [
    "\n",
    "f1 = f1_score(y_test, y_pred, average='macro')\n",
    "print(f\"F1 Score: {f1}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f26a5a90",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "id": "74fc096e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test = pd.read_csv('test.txt', header = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "id": "7792e4af",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_features = []\n",
    "test_data = []\n",
    "test_row_indices = []\n",
    "test_col_indices = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "id": "cea3cfe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0, data_test.shape[0]):\n",
    "    data_point = list(filter(lambda x: x.strip() != \"\", data_test.iloc[i][0].replace(\"\\t\", \" \").split(\" \")))\n",
    "    data_point = list(map(int, data_point))\n",
    "    test_features.append(data_point)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "id": "153cd7dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, indices in enumerate(test_features):\n",
    "    test_data.extend([1] * len(indices))  # Assuming all values are 1\n",
    "    test_row_indices.extend([i] * len(indices))\n",
    "    test_col_indices.extend(indices)\n",
    "\n",
    "\n",
    "num_rows = len(test_features)\n",
    "num_columns = max(max(indices) for indices in features) + 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "id": "1d88e00d",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sparse_matrix = csr_matrix((test_data, (test_row_indices, test_col_indices)), shape=(num_rows, num_columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "id": "e2ee4cb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "active_indices = np.where(np.array(y_train) == 1)[0]\n",
    "inactive_indices = np.where(np.array(y_train) == 0)[0]\n",
    "y_train = np.array(y_train)\n",
    "\n",
    "all_predictions = []\n",
    "used_inactive_indices = []\n",
    "\n",
    "\n",
    "num_models = 10  \n",
    "for i in range(num_models):\n",
    "    \n",
    "    num_inactive_samples = min(150, len(inactive_indices))\n",
    "\n",
    "    \n",
    "    unused_inactive_indices = list(set(inactive_indices) - set(used_inactive_indices))\n",
    "\n",
    "    \n",
    "    if len(unused_inactive_indices) < num_inactive_samples:\n",
    "        unused_inactive_indices = list(set(inactive_indices))\n",
    "\n",
    "    random_inactive_indices = np.random.choice(unused_inactive_indices, num_inactive_samples, replace=False)\n",
    "\n",
    " \n",
    "    used_inactive_indices.extend(random_inactive_indices)\n",
    "\n",
    " \n",
    "    balanced_indices = np.concatenate([active_indices, random_inactive_indices])\n",
    "\n",
    "\n",
    "   \n",
    "    X_balanced = X_train[balanced_indices]\n",
    "    y_balanced = y_train[balanced_indices]\n",
    "    X_train_new = k_best.fit_transform(X_balanced, y_balanced)\n",
    "    \n",
    "    model = mlp_classifier = MLPClassifier(hidden_layer_sizes=(64, 32), alpha=1e-5, activation='relu', solver='adam', random_state=42)\n",
    "\n",
    "    model.fit(X_train_new, y_balanced)\n",
    "    X_test_set = k_best.transform(test_sparse_matrix)\n",
    "    \n",
    "    y_pred = model.predict(X_test_set)\n",
    "\n",
    "    \n",
    "    all_predictions.append(y_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "id": "5744ec2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred = np.logical_and.reduce(all_predictions).astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "id": "af9229d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = \"formatfile.txt\"\n",
    "\n",
    "\n",
    "with open(file_name, 'w') as file:\n",
    "    for prediction in y_test_pred:\n",
    "        file.write(str(prediction) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "id": "2506daee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "350\n"
     ]
    }
   ],
   "source": [
    "print(len(y_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a535145b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
